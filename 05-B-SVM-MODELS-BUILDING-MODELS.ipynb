{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import pmdarima as pm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.dates as dates\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_7 = pd.read_csv(\"daily_data_seasonality_7.csv\",header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "daily_data_14 = pd.read_csv(\"daily_data_seasonality_14.csv\",header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "daily_data_21 = pd.read_csv(\"daily_data_seasonality_21.csv\",header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "daily_data_28 = pd.read_csv(\"daily_data_seasonality_28.csv\",header=0, index_col=0, parse_dates=True, squeeze=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing periods\n",
    "train_start = '2016-01-01'\n",
    "train_end = '2018-12-31'\n",
    "test_start = '2019-01-01'\n",
    "test_end = '2019-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up into training and testing sets\n",
    "\n",
    "# _7 days window\n",
    "X_train_df_7 = daily_data_7[train_start:train_end]\n",
    "del X_train_df_7['Consumption']\n",
    "\n",
    "\n",
    "y_train_df_7 = daily_data_7['Consumption'][train_start:train_end]\n",
    "\n",
    "X_test_df_7 = daily_data_7[test_start:test_end]\n",
    "del X_test_df_7['Consumption']\n",
    "\n",
    "y_test_df_7 = daily_data_7['Consumption'][test_start:test_end]\n",
    "\n",
    "# _14 days window\n",
    "X_train_df_14 = daily_data_14[train_start:train_end]\n",
    "del X_train_df_14['Consumption']\n",
    "\n",
    "\n",
    "y_train_df_14 = daily_data_14['Consumption'][train_start:train_end]\n",
    "\n",
    "X_test_df_14 = daily_data_14[test_start:test_end]\n",
    "del X_test_df_14['Consumption']\n",
    "\n",
    "y_test_df_14 = daily_data_14['Consumption'][test_start:test_end]\n",
    "\n",
    "# _21 days window\n",
    "X_train_df_21 = daily_data_21[train_start:train_end]\n",
    "del X_train_df_21['Consumption']\n",
    "\n",
    "\n",
    "y_train_df_21 = daily_data_21['Consumption'][train_start:train_end]\n",
    "\n",
    "X_test_df_21 = daily_data_21[test_start:test_end]\n",
    "del X_test_df_21['Consumption']\n",
    "\n",
    "y_test_df_21 = daily_data_21['Consumption'][test_start:test_end]\n",
    "\n",
    "# _28 days window\n",
    "X_train_df_28 = daily_data_28[train_start:train_end]\n",
    "del X_train_df_28['Consumption']\n",
    "\n",
    "\n",
    "y_train_df_28 = daily_data_28['Consumption'][train_start:train_end]\n",
    "\n",
    "X_test_df_28 = daily_data_28[test_start:test_end]\n",
    "del X_test_df_28['Consumption']\n",
    "\n",
    "y_test_df_28 = daily_data_28['Consumption'][test_start:test_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use sklearn, they need to be converted to NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy arrays for sklearn\n",
    "\n",
    "# _7 days\n",
    "X_train_7 = np.array(X_train_df_7)\n",
    "X_test_7 = np.array(X_test_df_7)\n",
    "y_train_7 = np.array(y_train_df_7)\n",
    "y_test_7 = np.array(y_test_df_7)\n",
    "\n",
    "# _14 days\n",
    "X_train_14 = np.array(X_train_df_14)\n",
    "X_test_14 = np.array(X_test_df_14)\n",
    "y_train_14 = np.array(y_train_df_14)\n",
    "y_test_14 = np.array(y_test_df_14)\n",
    "\n",
    "# _21 days\n",
    "X_train_21 = np.array(X_train_df_21)\n",
    "X_test_21 = np.array(X_test_df_21)\n",
    "y_train_21 = np.array(y_train_df_21)\n",
    "y_test_21 = np.array(y_test_df_21)\n",
    "\n",
    "# _28 days\n",
    "X_train_28 = np.array(X_train_df_28)\n",
    "X_test_28 = np.array(X_test_df_28)\n",
    "y_train_28 = np.array(y_train_df_28)\n",
    "y_test_28 = np.array(y_test_df_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pre\n",
    "\n",
    "# _7 days\n",
    "scaler_7 = pre.StandardScaler().fit(X_train_7)\n",
    "X_train_scaled_7 = scaler_7.transform(X_train_7)\n",
    "X_test_scaled_7 = scaler_7.transform(X_test_7)\n",
    "\n",
    "# _14 days\n",
    "scaler_14 = pre.StandardScaler().fit(X_train_14)\n",
    "X_train_scaled_14 = scaler_14.transform(X_train_14)\n",
    "X_test_scaled_14 = scaler_14.transform(X_test_14)\n",
    "\n",
    "# _21 days\n",
    "scaler_21 = pre.StandardScaler().fit(X_train_21)\n",
    "X_train_scaled_21 = scaler_21.transform(X_train_21)\n",
    "X_test_scaled_21 = scaler_21.transform(X_test_21)\n",
    "\n",
    "# _28 days\n",
    "scaler_28 = pre.StandardScaler().fit(X_train_28)\n",
    "X_train_scaled_28 = scaler_28.transform(X_train_28)\n",
    "X_test_scaled_28 = scaler_28.transform(X_test_28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-days window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_7_rbf= svm.SVR(kernel='rbf',C=20000, gamma=0.01, cache_size=10000).fit(X_train_scaled_7,y_train_7)\n",
    "grid_model_7_lin = svm.LinearSVR(C=510000,max_iter=1000000).fit(X_train_scaled_7,y_train_7)\n",
    "random_model_7_rbf = svm.SVR(kernel='rbf',C=886663.4812532668, gamma=0.01, cache_size=10000).fit(X_train_scaled_7,y_train_7)\n",
    "random_model_7_lin = svm.LinearSVR(C=850162.5654928379,max_iter=1000000).fit(X_train_scaled_7,y_train_7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predict_y_array_rbf_7 = grid_model_7_rbf.predict(X_test_scaled_7)\n",
    "grid_predict_y_array_lin_7 = grid_model_7_lin.predict(X_test_scaled_7)\n",
    "random_predict_y_array_rbf_7 = grid_model_7_rbf.predict(X_test_scaled_7)\n",
    "random_predict_y_array_lin_7 = random_model_7_lin.predict(X_test_scaled_7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random_lin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_7 = {}\n",
    "mape_7['grid_rbf'] = (abs((y_test_df_7 - grid_predict_y_array_rbf_7)/y_test_df_7)*100).mean()\n",
    "mape_7['grid_lin'] = (abs((y_test_df_7 - grid_predict_y_array_lin_7)/y_test_df_7)*100).mean()\n",
    "mape_7['random_rbf'] = (abs((y_test_df_7 - random_predict_y_array_rbf_7)/y_test_df_7)*100).mean()\n",
    "mape_7['random_lin'] = (abs((y_test_df_7 - random_predict_y_array_lin_7)/y_test_df_7)*100).mean()\n",
    "\n",
    "min(mape_7, key=mape_7.get) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14-days window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_14_rbf= svm.SVR(kernel='rbf',C=20000, gamma=0.01, cache_size=10000).fit(X_train_scaled_14,y_train_14)\n",
    "grid_model_14_lin = svm.LinearSVR(C=940000,max_iter=1000000).fit(X_train_scaled_14,y_train_14)\n",
    "random_model_14_rbf = svm.SVR(kernel='rbf',C=886968.1405918691, gamma=0.01, cache_size=10000).fit(X_train_scaled_14,y_train_14)\n",
    "random_model_14_lin = svm.LinearSVR(C=771683.9396441513,max_iter=1000000).fit(X_train_scaled_14,y_train_14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predict_y_array_rbf_14 = grid_model_14_rbf.predict(X_test_scaled_14)\n",
    "grid_predict_y_array_lin_14 = grid_model_14_lin.predict(X_test_scaled_14)\n",
    "random_predict_y_array_rbf_14 = grid_model_14_rbf.predict(X_test_scaled_14)\n",
    "random_predict_y_array_lin_14 = random_model_14_lin.predict(X_test_scaled_14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grid_lin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mape_14 = {}\n",
    "mape_14['grid_rbf'] = (abs((y_test_df_14 - grid_predict_y_array_rbf_14)/y_test_df_14)*100).mean()\n",
    "mape_14['grid_lin'] = (abs((y_test_df_14 - grid_predict_y_array_lin_14)/y_test_df_14)*100).mean()\n",
    "mape_14['random_rbf'] = (abs((y_test_df_14 - random_predict_y_array_rbf_14)/y_test_df_14)*100).mean()\n",
    "mape_14['random_lin'] = (abs((y_test_df_14 - random_predict_y_array_lin_14)/y_test_df_14)*100).mean()\n",
    "\n",
    "min(mape_14, key=mape_14.get) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_rbf': 3.027705898179774,\n",
       " 'grid_lin': 2.4040273945009862,\n",
       " 'random_rbf': 3.027705898179774,\n",
       " 'random_lin': 2.4047837664796217}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21-days window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_21_rbf= svm.SVR(kernel='rbf',C=20000, gamma=0.01, cache_size=10000).fit(X_train_scaled_21,y_train_21)\n",
    "grid_model_21_lin = svm.LinearSVR(C=900000,max_iter=1000000).fit(X_train_scaled_21,y_train_21)\n",
    "random_model_21_rbf = svm.SVR(kernel='rbf',C=887135.4162493473, gamma=0.01, cache_size=10000).fit(X_train_scaled_21,y_train_21)\n",
    "random_model_21_lin = svm.LinearSVR(C=834611.6566123376,max_iter=1000000).fit(X_train_scaled_21,y_train_21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_predict_y_array_rbf_21 = grid_model_21_rbf.predict(X_test_scaled_21)\n",
    "grid_predict_y_array_lin_21 = grid_model_21_lin.predict(X_test_scaled_21)\n",
    "random_predict_y_array_rbf_21 = grid_model_21_rbf.predict(X_test_scaled_21)\n",
    "random_predict_y_array_lin_21 = random_model_21_lin.predict(X_test_scaled_21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random_lin'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_21 = {}\n",
    "mape_21['grid_rbf'] = (abs((y_test_df_21 - grid_predict_y_array_rbf_21)/y_test_df_21)*100).mean()\n",
    "mape_21['grid_lin'] = (abs((y_test_df_21 - grid_predict_y_array_lin_21)/y_test_df_21)*100).mean()\n",
    "mape_21['random_rbf'] = (abs((y_test_df_21 - random_predict_y_array_rbf_21)/y_test_df_21)*100).mean()\n",
    "mape_21['random_lin'] = (abs((y_test_df_21 - random_predict_y_array_lin_21)/y_test_df_21)*100).mean()\n",
    "\n",
    "min(mape_21, key=mape_21.get) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28-days window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_28_rbf= svm.SVR(kernel='rbf',C=10000, gamma=0.01, cache_size=10000).fit(X_train_scaled_28,y_train_28)\n",
    "grid_model_28_lin = svm.LinearSVR(C=840000,max_iter=1000000).fit(X_train_scaled_28,y_train_28)\n",
    "random_model_28_rbf = svm.SVR(kernel='rbf',C=887225.2618243571, gamma=0.01, cache_size=10000).fit(X_train_scaled_28,y_train_28)\n",
    "random_model_28_lin = svm.LinearSVR(C=771610.0024368193,max_iter=1000000).fit(X_train_scaled_28,y_train_28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predict_y_array_rbf_28 = grid_model_28_rbf.predict(X_test_scaled_28)\n",
    "grid_predict_y_array_lin_28 = grid_model_28_lin.predict(X_test_scaled_28)\n",
    "random_predict_y_array_rbf_28 = grid_model_28_rbf.predict(X_test_scaled_28)\n",
    "random_predict_y_array_lin_28 = random_model_28_lin.predict(X_test_scaled_28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random_lin'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_28 = {}\n",
    "mape_28['grid_rbf'] = (abs((y_test_df_28 - grid_predict_y_array_rbf_28)/y_test_df_28)*100).mean()\n",
    "mape_28['grid_lin'] = (abs((y_test_df_28 - grid_predict_y_array_lin_28)/y_test_df_28)*100).mean()\n",
    "mape_28['random_rbf'] = (abs((y_test_df_28 - random_predict_y_array_rbf_28)/y_test_df_28)*100).mean()\n",
    "mape_28['random_lin'] = (abs((y_test_df_28 - random_predict_y_array_lin_28)/y_test_df_28)*100).mean()\n",
    "\n",
    "min(mape_28, key=mape_28.get) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapes = {}\n",
    "mapes[\"SVM-7-days\"] = mape_7[min(mape_7, key=mape_7.get)]\n",
    "mapes[\"SVM-14-days\"] = mape_14[min(mape_14, key=mape_14.get)]\n",
    "mapes[\"SVM-21-days\"] = mape_21[min(mape_21, key=mape_21.get)]\n",
    "mapes[\"SVM-28-days\"] = mape_28[min(mape_28, key=mape_28.get)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVM-28-days'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(mapes, key=mapes.get) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random_lin'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(mape_28, key=mape_28.get) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best RNN model is 28-days feature with Linear kernel which is tuned by RandomSearchCV. \n",
    "### Save predicts to future comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_column = pd.date_range(start ='2019-1-1', end = '2019-12-31', freq ='D')\n",
    "best_pred = pd.DataFrame(data=random_predict_y_array_lin_28,\n",
    "              index=index_column)\n",
    "best_pred.rename(columns={0 : \"Consumption\"}, inplace=True)\n",
    "best_pred.to_csv(\"the_best_svr_pred.csv\",index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapes_df = pd.DataFrame.from_dict(mapes, orient='index')\n",
    "mapes_df.to_csv(\"mapes_svm.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
